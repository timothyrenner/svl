{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to SVL SVL is a declarative, SQL-like language for dashboards and reports. It's designed to make it very easy to build simple or complex collections of plots for data in flat tabular files. Like SQL, there are no variables, loops, if/else statements or data structures. You declare your datasets, describe the charts you want built and how they're arranged, and SVL will produce an HTML file with your plots. Installation To install SVL, you need Python 3.5+ and pip. If you've got that ready, install with pip install -U svl After that, you're all set. Quickstart I've bundled a trimmed-down sample dataset of Bigfoot sightings for the quickstart and tutorials. You're welcome. After SVL has been installed, download the sample dataset from Github . wget https://raw.githubusercontent.com/timothyrenner/svl/master/sample_data/bigfoot_sightings.csv In the same directory as the dataset, create a file named quickstart.svl and paste the following code in it. DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot X date BY YEAR Y number COUNT SPLIT BY classification CONCAT( HISTOGRAM bigfoot X temperature_mid HISTOGRAM bigfoot X humidity ) \ud83c\udf89 This is a complete SVL program. \ud83c\udf89 Compile it by running this in your shell. svl quickstart.svl You should see a browser window pop up that looks something like this: (interactive version here ) SVL also saved this visualization as visualization.html in the directory where it was run. If you'd like to read more about what's in SVL and why I created it, read on! Or maybe you want to go deeper and head into the tutorials . SVL is... Simple - no variables, control flow statements, or data structures. Just like SQL. Easy - syntax feels like SQL, with actual SQL support for in-script data manipulation. Small - the entire grammar is under 150 lines long. Alpha Features \u2705 Easy to learn : The entire grammar is under 150 lines. 6\ufe0f\u20e3 Chart types : Line, bar, scatter, histogram and pie. And number. I plan on adding more, so if I'm missing your favorite one let me know. \ud83d\udcc8 Complex layouts : SVL scripts can support any number of plots and makes it straightforward to arrange them so that the most important plots get the most real estate. \ud83d\udcca Interactive HTML output : SVL uses Plotly to draw the visualizations, and produces an easily shareable but still interactive HTML file. \ud83d\udcc2 CSV and Parquet files : Currently the data is limited to files, and SVL has support for CSV and (if pyarrow is installed) parquet files. Not Alpha Features, but Possible Other plot backends The compiler isn't married to Plotly. SVL can have future support for other backends like Vega, Bokeh, or even Matplotlib (probably). Other data sources For simplicity SVL operates on files, but like the plot renderer the compiler isn't coupled to flat files. In fact, most of the data processing is done under the hood by SQLite , so adding support for other data processors like Postgres or MySQL is definitely possible. Other plot types I picked those five for the alpha release because they're the most common, but obviously more support can be added. Let me know what other chart types you'd like to see! Why SVL I do data science and machine learning for a living, so I make a lot of plots. Some of those plots are for exploratory purposes inside a notebook environment, and usually I use Seaborn or, more recently, Chartify . If I'm in R (which isn't too often these days), obviously ggplot is the way to go. All of these libraries are great and offer a nice balance of customizability and conciseness when building individual plots. There are two things I notice while I'm working with these tools. I can never remember enough commands to make a plot without consulting documentation. Never. Maybe I just don't do it enough, but these libraries have complicated APIs and I can't keep them in my head. I tend to make the same kinds of plots over and over again. Yes there are all sorts of powerful things you can do with these libraries to make publication-quality charts, but honestly I pretty much just make scatter plots and histograms and like one bar chart per project. There's another scenario I use plots for - operational metrics. When I execute a training / offline prediction run for a machine learning model, I want to visualize a whole bunch of stuff all at once to get a \"feel\" for what the model's doing with the features, as well as the kind of impacts we'll expect to put onto our downstream consumers. These are basically operational dashboards (like what you'd make with Splunk or Datadog), but for machine learning models in an offline environment. For these plots I don't want super customized stuff, I just want simple visualizations to give me a feel for what's going on in one place. Now I could just have a notebook that does this for me - in fact the Lore framework from Instacart takes this approach, but there are a number of issues with using a notebook for operational stuff: difficult to automate (some progress has been made in this area recently) difficult to version (hey, another repo that's 99.8% \"Jupyter Notebook\"!) difficult to share (maybe nobody wants to see bad notebook code?) I do often write scripts for operational plots for these ML pipelines, but it's a lot of work. There's the verbosity of the plots themselves, plus I have to read the data myself, then I have to write the code for laying the plots out so they're visually coherent. Those scripts easily blow up to hundreds of lines of code. I found myself wishing there was some way for me to just write a plot like this: SCATTER dataset X field1 Y field2 If dataset were a table or file with field1 and field2 this would be really easy to remember. Better still, if I could put multiple plots like this in one script file, I could control which plots appear together to make it easier to get a feel for the data. Like if I wanted histograms of field1 and field2 underneath my scatter plot I could write: SCATTER dataset X field1 Y field2 CONCAT ( HISTOGRAM dataset X field1 HISTOGRAM dataset X field2 ) and the scatter plot would be on top, and the histograms would be next to each other underneath it. I wanted a tool with these characteristics: small and easy to remember combines plots easily allows data processing and transformations I created SVL (name and syntax inspired by SQL) with these three priorities in mind. For 1, I decided to create a declarative DSL rather than a library because a library must exist in the broader context of a fully fledged programming language. That means I have to represent plot inputs and outputs using abstractions provided by the language - variables / objects. This can get complicated, particularly the inputs. Sometimes that complication is justified, but for most of the plots I make it isn't. With a declarative DSL I don't have to worry about variables or objects, the compiler figures out what needs to be done - just like SQL. For 2, I created operators for vertical and horizontal concatenation. If you want vertical concatenation, just put two plot declarations next to each other. If you want horizontal concatenation, put them inside CONCAT . These operations compose, allowing for arbitrary nesting (under the hood plots are represented as a tree). Using these operators is much simpler than trying to put everything on a grid, especially when there are a lot of plots you want to make. It gets translated to a grid eventually (and yes it is complicated), but the compiler takes care of that. For 3, I decoupled the data source representations from the compiler. The advantage is that any transformations can be written in the language native to the data source. The compiler would then just pass those transformations directly to the data source before it builds the plots. Right now that's just SQL because the only backend I've written is SQLite, but in principle any data source is possible. All that's required is code to transform the data returned by the data source into the structures the plots need. My goal in creating SVL isn't to replace my usual set of plotting tools, it's to get me making more plots, faster . Most of what I use it for currently is basically reporting - answering the question \"what's in the dataset?\" concisely. Hopefully you will find SVL as useful as I do.","title":"Home"},{"location":"#welcome-to-svl","text":"SVL is a declarative, SQL-like language for dashboards and reports. It's designed to make it very easy to build simple or complex collections of plots for data in flat tabular files. Like SQL, there are no variables, loops, if/else statements or data structures. You declare your datasets, describe the charts you want built and how they're arranged, and SVL will produce an HTML file with your plots.","title":"Welcome to SVL"},{"location":"#installation","text":"To install SVL, you need Python 3.5+ and pip. If you've got that ready, install with pip install -U svl After that, you're all set.","title":"Installation"},{"location":"#quickstart","text":"I've bundled a trimmed-down sample dataset of Bigfoot sightings for the quickstart and tutorials. You're welcome. After SVL has been installed, download the sample dataset from Github . wget https://raw.githubusercontent.com/timothyrenner/svl/master/sample_data/bigfoot_sightings.csv In the same directory as the dataset, create a file named quickstart.svl and paste the following code in it. DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot X date BY YEAR Y number COUNT SPLIT BY classification CONCAT( HISTOGRAM bigfoot X temperature_mid HISTOGRAM bigfoot X humidity ) \ud83c\udf89 This is a complete SVL program. \ud83c\udf89 Compile it by running this in your shell. svl quickstart.svl You should see a browser window pop up that looks something like this: (interactive version here ) SVL also saved this visualization as visualization.html in the directory where it was run. If you'd like to read more about what's in SVL and why I created it, read on! Or maybe you want to go deeper and head into the tutorials .","title":"Quickstart"},{"location":"#svl-is","text":"Simple - no variables, control flow statements, or data structures. Just like SQL. Easy - syntax feels like SQL, with actual SQL support for in-script data manipulation. Small - the entire grammar is under 150 lines long.","title":"SVL is..."},{"location":"#alpha-features","text":"\u2705 Easy to learn : The entire grammar is under 150 lines. 6\ufe0f\u20e3 Chart types : Line, bar, scatter, histogram and pie. And number. I plan on adding more, so if I'm missing your favorite one let me know. \ud83d\udcc8 Complex layouts : SVL scripts can support any number of plots and makes it straightforward to arrange them so that the most important plots get the most real estate. \ud83d\udcca Interactive HTML output : SVL uses Plotly to draw the visualizations, and produces an easily shareable but still interactive HTML file. \ud83d\udcc2 CSV and Parquet files : Currently the data is limited to files, and SVL has support for CSV and (if pyarrow is installed) parquet files.","title":"Alpha Features"},{"location":"#not-alpha-features-but-possible","text":"Other plot backends The compiler isn't married to Plotly. SVL can have future support for other backends like Vega, Bokeh, or even Matplotlib (probably). Other data sources For simplicity SVL operates on files, but like the plot renderer the compiler isn't coupled to flat files. In fact, most of the data processing is done under the hood by SQLite , so adding support for other data processors like Postgres or MySQL is definitely possible. Other plot types I picked those five for the alpha release because they're the most common, but obviously more support can be added. Let me know what other chart types you'd like to see!","title":"Not Alpha Features, but Possible"},{"location":"#why-svl","text":"I do data science and machine learning for a living, so I make a lot of plots. Some of those plots are for exploratory purposes inside a notebook environment, and usually I use Seaborn or, more recently, Chartify . If I'm in R (which isn't too often these days), obviously ggplot is the way to go. All of these libraries are great and offer a nice balance of customizability and conciseness when building individual plots. There are two things I notice while I'm working with these tools. I can never remember enough commands to make a plot without consulting documentation. Never. Maybe I just don't do it enough, but these libraries have complicated APIs and I can't keep them in my head. I tend to make the same kinds of plots over and over again. Yes there are all sorts of powerful things you can do with these libraries to make publication-quality charts, but honestly I pretty much just make scatter plots and histograms and like one bar chart per project. There's another scenario I use plots for - operational metrics. When I execute a training / offline prediction run for a machine learning model, I want to visualize a whole bunch of stuff all at once to get a \"feel\" for what the model's doing with the features, as well as the kind of impacts we'll expect to put onto our downstream consumers. These are basically operational dashboards (like what you'd make with Splunk or Datadog), but for machine learning models in an offline environment. For these plots I don't want super customized stuff, I just want simple visualizations to give me a feel for what's going on in one place. Now I could just have a notebook that does this for me - in fact the Lore framework from Instacart takes this approach, but there are a number of issues with using a notebook for operational stuff: difficult to automate (some progress has been made in this area recently) difficult to version (hey, another repo that's 99.8% \"Jupyter Notebook\"!) difficult to share (maybe nobody wants to see bad notebook code?) I do often write scripts for operational plots for these ML pipelines, but it's a lot of work. There's the verbosity of the plots themselves, plus I have to read the data myself, then I have to write the code for laying the plots out so they're visually coherent. Those scripts easily blow up to hundreds of lines of code. I found myself wishing there was some way for me to just write a plot like this: SCATTER dataset X field1 Y field2 If dataset were a table or file with field1 and field2 this would be really easy to remember. Better still, if I could put multiple plots like this in one script file, I could control which plots appear together to make it easier to get a feel for the data. Like if I wanted histograms of field1 and field2 underneath my scatter plot I could write: SCATTER dataset X field1 Y field2 CONCAT ( HISTOGRAM dataset X field1 HISTOGRAM dataset X field2 ) and the scatter plot would be on top, and the histograms would be next to each other underneath it. I wanted a tool with these characteristics: small and easy to remember combines plots easily allows data processing and transformations I created SVL (name and syntax inspired by SQL) with these three priorities in mind. For 1, I decided to create a declarative DSL rather than a library because a library must exist in the broader context of a fully fledged programming language. That means I have to represent plot inputs and outputs using abstractions provided by the language - variables / objects. This can get complicated, particularly the inputs. Sometimes that complication is justified, but for most of the plots I make it isn't. With a declarative DSL I don't have to worry about variables or objects, the compiler figures out what needs to be done - just like SQL. For 2, I created operators for vertical and horizontal concatenation. If you want vertical concatenation, just put two plot declarations next to each other. If you want horizontal concatenation, put them inside CONCAT . These operations compose, allowing for arbitrary nesting (under the hood plots are represented as a tree). Using these operators is much simpler than trying to put everything on a grid, especially when there are a lot of plots you want to make. It gets translated to a grid eventually (and yes it is complicated), but the compiler takes care of that. For 3, I decoupled the data source representations from the compiler. The advantage is that any transformations can be written in the language native to the data source. The compiler would then just pass those transformations directly to the data source before it builds the plots. Right now that's just SQL because the only backend I've written is SQLite, but in principle any data source is possible. All that's required is code to transform the data returned by the data source into the structures the plots need. My goal in creating SVL isn't to replace my usual set of plotting tools, it's to get me making more plots, faster . Most of what I use it for currently is basically reporting - answering the question \"what's in the dataset?\" concisely. Hopefully you will find SVL as useful as I do.","title":"Why SVL"},{"location":"reference/syntax_reference/","text":"Syntax Reference This is a reference manual for the SVL syntax. Notation (these are not syntax): [ ] means optional | is a logical OR. { } is for grouping logical ORs when it's not obvious. ... means the previous pattern is repeated. If this method turns out to be incomprehensible I'll figure something else out. A Repeat of Boring Stuff I mean this whole article is boring stuff, but this stuff is really boring. All keywords in SVL are case- insensitive , but field names, file names, and anything in quotes are not. By convention I will capitalize keywords but it's not required. Comments start with -- and extend to the end of the line. All dataset and field names (basically anything not in quotes) must start with an underscore or letter, and can only contain letters, underscores or digits. SVL is not sensitive to tabs or newlines. The entire program could be written on one line if you wanted. Scripts Schematically, an entire SVL program looks like this. [DATASETS dataset declaration, ...] chart | CONCAT(chart, ...) | (chart, ...), ... Dataset declarations and charts are described below. DATASETS is optional. After that you can create one or more charts, each of which is a chart by itself, a horizontal concatenation of one or more charts, or a vertical concatenation of one or more charts. DATASETS Dataset declarations are made up of file declarations or SQL declarations. DATASETS identifier {file_path | SQL sql_query}, ... sql_query and file_path are double quoted strings. NOTE There has to be at least one file in the final program, which can either be declared in the script or passed in via the command line. SCATTER SCATTER dataset_identifier { x_axis | y_axis | [ FILTER quoted_string ] | [ TITLE quoted_string ] | [ split_by ] | [ color_by ] }, ... Scatter requires an X and Y axis. The quoted string following FILTER must be a valid SQL WHERE expression. SPLIT BY and COLOR BY cannot both be present. HISTOGRAM HISTOGRAM dataset_identifier { x_axis | y_axis | [ FILTER quoted_string ] | [ TITLE quoted_string ] | [ split_by ] | [ STEP number ] | [ BINS integer ] }, ... STEP will take any positive floating point number or integer. BINS will take any positive integer. HISTOGRAM can have an X or Y axis, but not both. The quoted string following FILTER must be a valid SQL WHERE expression. LINE LINE dataset_identifier { x_axis | y_axis | [ FILTER quoted_string ] | [ TITLE quoted_string ] | [ split_by ] | [ color_by ] }, ... LINE requires both an X and Y axis. The quoted string following FILTER must be a valid SQL WHERE expression. SPLIT BY and COLOR BY cannot both be present. BAR BAR dataset_identifier { x_axis | y_axis | [ FILTER quoted_string ] | [ TITLE quoted_string ] | [ split_by ] | [ color_by ] } BAR requires both an X and Y axis. The quoted string following FILTER must be a valid SQL WHERE expression. SPLIT BY and COLOR BY cannot both be present. PIE PIE dataset_identifier { axis | [ FILTER quoted_string ] | [ TITLE quoted_string ] | [ HOLE number ] }, ... PIE requires one AXIS . The quoted string following FILTER must be a valid SQL WHERE expression. HOLE must take a floating point number between zero and one. NUMBER NUMBER dataset_identifier { value | [ FILTER quoted_string ] | [ TITLE quoted_string ] }, ... NUMBER requires one VALUE . If the provided value doesn't resolve to a single number, SVL will raise an error. X , Y , AXIS . VALUE X , Y and AXIS all take the same properties. VALUE can only be aggregated. It does not accept temporal modifiers, labels or sorts. {X | Y | AXIS | VALUE} {field_identifier | TRANSFORM quoted_string} [ AGG | BY temporal | LABEL quoted_string | SORT {ASC | DESC} ], ... The quoted string following TRANSFORM must be a valid SQL SELECT expression. AGG is one of COUNT , MIN , MAX , AVG , SUM . Temporal is one of YEAR , MONTH , DAY , HOUR , MINUTE , SECOND . SPLIT BY SPLIT BY {field_identifier | TRANSFORM quoted_string} [BY temporal | LABEL quoted_string], ... The quoted string following TRANSFORM must be a valid SQL SELECT expression. Temporal is one of YEAR , MONTH , DAY , HOUR , MINUTE , SECOND . For the Plotly backend (currently the only one available), LABEL is a no-op, since adding legend titles to charts is fairly challenging for Plotly plots. COLOR BY COLOR BY {field_identifier | TRANSFORM quoted_string} [ AGG | BY temporal | LABEL quoted_string | color_scale ], ... The quoted string following TRANSFORM must be a valid SQL SELECT expression. AGG is one of COUNT , MIN , MAX , AVG . Temporal is one of YEAR , MONTH , DAY , HOUR , MINUTE , SECOND . Color scale is a quoted string that corresponds to (for now) a Plotly color scale .","title":"Syntax"},{"location":"reference/syntax_reference/#syntax-reference","text":"This is a reference manual for the SVL syntax. Notation (these are not syntax): [ ] means optional | is a logical OR. { } is for grouping logical ORs when it's not obvious. ... means the previous pattern is repeated. If this method turns out to be incomprehensible I'll figure something else out.","title":"Syntax Reference"},{"location":"reference/syntax_reference/#a-repeat-of-boring-stuff","text":"I mean this whole article is boring stuff, but this stuff is really boring. All keywords in SVL are case- insensitive , but field names, file names, and anything in quotes are not. By convention I will capitalize keywords but it's not required. Comments start with -- and extend to the end of the line. All dataset and field names (basically anything not in quotes) must start with an underscore or letter, and can only contain letters, underscores or digits. SVL is not sensitive to tabs or newlines. The entire program could be written on one line if you wanted.","title":"A Repeat of Boring Stuff"},{"location":"reference/syntax_reference/#scripts","text":"Schematically, an entire SVL program looks like this. [DATASETS dataset declaration, ...] chart | CONCAT(chart, ...) | (chart, ...), ... Dataset declarations and charts are described below. DATASETS is optional. After that you can create one or more charts, each of which is a chart by itself, a horizontal concatenation of one or more charts, or a vertical concatenation of one or more charts.","title":"Scripts"},{"location":"reference/syntax_reference/#datasets","text":"Dataset declarations are made up of file declarations or SQL declarations. DATASETS identifier {file_path | SQL sql_query}, ... sql_query and file_path are double quoted strings. NOTE There has to be at least one file in the final program, which can either be declared in the script or passed in via the command line.","title":"DATASETS"},{"location":"reference/syntax_reference/#scatter","text":"SCATTER dataset_identifier { x_axis | y_axis | [ FILTER quoted_string ] | [ TITLE quoted_string ] | [ split_by ] | [ color_by ] }, ... Scatter requires an X and Y axis. The quoted string following FILTER must be a valid SQL WHERE expression. SPLIT BY and COLOR BY cannot both be present.","title":"SCATTER"},{"location":"reference/syntax_reference/#histogram","text":"HISTOGRAM dataset_identifier { x_axis | y_axis | [ FILTER quoted_string ] | [ TITLE quoted_string ] | [ split_by ] | [ STEP number ] | [ BINS integer ] }, ... STEP will take any positive floating point number or integer. BINS will take any positive integer. HISTOGRAM can have an X or Y axis, but not both. The quoted string following FILTER must be a valid SQL WHERE expression.","title":"HISTOGRAM"},{"location":"reference/syntax_reference/#line","text":"LINE dataset_identifier { x_axis | y_axis | [ FILTER quoted_string ] | [ TITLE quoted_string ] | [ split_by ] | [ color_by ] }, ... LINE requires both an X and Y axis. The quoted string following FILTER must be a valid SQL WHERE expression. SPLIT BY and COLOR BY cannot both be present.","title":"LINE"},{"location":"reference/syntax_reference/#bar","text":"BAR dataset_identifier { x_axis | y_axis | [ FILTER quoted_string ] | [ TITLE quoted_string ] | [ split_by ] | [ color_by ] } BAR requires both an X and Y axis. The quoted string following FILTER must be a valid SQL WHERE expression. SPLIT BY and COLOR BY cannot both be present.","title":"BAR"},{"location":"reference/syntax_reference/#pie","text":"PIE dataset_identifier { axis | [ FILTER quoted_string ] | [ TITLE quoted_string ] | [ HOLE number ] }, ... PIE requires one AXIS . The quoted string following FILTER must be a valid SQL WHERE expression. HOLE must take a floating point number between zero and one.","title":"PIE"},{"location":"reference/syntax_reference/#number","text":"NUMBER dataset_identifier { value | [ FILTER quoted_string ] | [ TITLE quoted_string ] }, ... NUMBER requires one VALUE . If the provided value doesn't resolve to a single number, SVL will raise an error.","title":"NUMBER"},{"location":"reference/syntax_reference/#x-y-axis-value","text":"X , Y and AXIS all take the same properties. VALUE can only be aggregated. It does not accept temporal modifiers, labels or sorts. {X | Y | AXIS | VALUE} {field_identifier | TRANSFORM quoted_string} [ AGG | BY temporal | LABEL quoted_string | SORT {ASC | DESC} ], ... The quoted string following TRANSFORM must be a valid SQL SELECT expression. AGG is one of COUNT , MIN , MAX , AVG , SUM . Temporal is one of YEAR , MONTH , DAY , HOUR , MINUTE , SECOND .","title":"X, Y, AXIS. VALUE"},{"location":"reference/syntax_reference/#split-by","text":"SPLIT BY {field_identifier | TRANSFORM quoted_string} [BY temporal | LABEL quoted_string], ... The quoted string following TRANSFORM must be a valid SQL SELECT expression. Temporal is one of YEAR , MONTH , DAY , HOUR , MINUTE , SECOND . For the Plotly backend (currently the only one available), LABEL is a no-op, since adding legend titles to charts is fairly challenging for Plotly plots.","title":"SPLIT BY"},{"location":"reference/syntax_reference/#color-by","text":"COLOR BY {field_identifier | TRANSFORM quoted_string} [ AGG | BY temporal | LABEL quoted_string | color_scale ], ... The quoted string following TRANSFORM must be a valid SQL SELECT expression. AGG is one of COUNT , MIN , MAX , AVG . Temporal is one of YEAR , MONTH , DAY , HOUR , MINUTE , SECOND . Color scale is a quoted string that corresponds to (for now) a Plotly color scale .","title":"COLOR BY"},{"location":"reference/under_the_hood/","text":"Under the Hood This document describes the structure of the compiler. I'll start by describing the compiler's stages in sequence, then present a diagram at the end with everything. The entire compiler is written in Python, with a sprinkling of HTML / JS to render the final HTML page. Parsing The language itself is defined as an EBNF grammar designed to be parsed by the freaking awesome Lark parser. The grammar itself is defined in this file . This probably isn't the cleanest representation (I've never done this before / don't have formal CS training), but it gets the job done. Lark takes the grammar specification and the input script and parses that into a bunch of custom objects. I've implemented an adapter to convert those objects into a python dictionary that provides a tree-like representation of the plots. The reason this is a tree has to do with CONCAT( ... ) and ( ... ) . A chart is defined as either a raw plot, or a concatenation of plots. This means they can nest within one another, which makes them a tree. Concretely, given this script: DATASETS bigfoot \"bigfoot_sightings.csv\" CONCAT( SCATTER bigfoot X latitude Y temperature_mid BAR bigfoot X classification Y classification COUNT ) the resulting tree looks like: { \"datasets\" : { \"bigfoot\" : { \"file\" : \"bigfoot_sightings.csv\" } }, \"vcat\" : [{ \"hcat\" : [ { \"data\" : \"bigfoot\" , \"type\" : \"scatter\" , \"x\" : { \"field\" : \"latitude\" }, \"y\" : { \"field\" : \"temperature_mid\" } }, { \"data\" : \"bigfoot\" , \"type\" : \"bar\" , \"x\" : { \"field\" : \"classification\" }, \"y\" : { \"agg\" : \"COUNT\" , \"field\" : \"classification\" } } ] }] } The outermost vcat (vertical concatenation) is always there, and inside that there's an hcat (horizontal concatenation). Either of the plots inside the hcat could itself be an hcat or vcat ... and on and on. Flattening the Plot Tree Trees are nice inside a programming environment, but I need these plots to get rendered onto a web page, which means I need to project the tree onto a grid. I implemented plot layouts with CSS grids because they're pretty straightforward once you get your head around it. Basically, CSS grids need a layout declaration, and each element in the grid needs a position. So I need to go from tree of plots to a list of plots that have grid positions. I can traverse the tree and track the position as I go, but there's a minor hiccup: CSS grids are uniform , but our plots aren't. If I've got one plot on one row, then there's only one CSS column / row. If I've got one plot on the first row and two on the second (via CONCAT ), then I need CSS to have two columns and two rows. If I've got one plot on the first row and three plots on the second row, but the two on the right are stacked, then I need 4 columns and 4 rows... and I need to ensure that the top plot takes up 2 rows and 4 columns, and so forth. Concretely, given this tree (I've replaced the plot details with simple dicts for readability)... { \"vcat\" : [ { \"hcat\" : [ { \"plot\" : 1 }, { \"plot\" : 2 } ] }, { \"vcat\" : [ { \"plot\" : 3 }, { \"plot\" : 4 } ] } ] } This tree puts two side-by-side plots on the first row, and two vertical plots on the second row. As real output this would look weird, but it's a good example. The first row of plots take up one column and two rows each, while the second row of plots take up one row and two columns each. SVL flattens the above to this list. [ { \"plot\" : 1 , \"row_start\" : 0 , \"row_end\" : 2 , \"column_start\" : 0 , \"column_end\" : 1 }, { \"plot\" : 2 , \"row_start\" : 0 , \"row_end\" : 2 , \"column_start\" : 1 , \"column_end\" : 2 }, { \"plot\" : 3 , \"row_start\" : 2 , \"row_end\" : 3 , \"column_start\" : 0 , \"column_end\" : 2 }, { \"plot\" : 4 , \"row_start\" : 3 , \"row_end\" : 4 , \"column_start\" : 0 , \"column_end\" : 2 } ] This piece of the compiler is complicated. It took me over 2 months to get this right. The unit tests for this algorithm total up to almost 700 lines of code. It's the only time I've ever used TDD (it worked very well for this). Loading the SQLite DB This piece is pretty straightforward. Because I'm lazy efficient, I decided to use pandas to read the files and load the SQLite database. Files are loaded first, then the SQL datasets are constructed in the order they appear in the script. Retrieving the Plot Data This functionality is the proud home of probably the worst code of the whole compiler (I'm going to refactor it soon because it makes my eyes bleed), but the functionality in principle is simple. It translates the SVL plot specifier (after flattening) into a SQL query, then marshals those results into something that can be injected into a Plotly data structure. For example, consider the following plot. { \"data\" : \"bigfoot\" , \"type\" : \"bar\" , \"x\" : { \"agg\" : \"AVG\" , \"field\" : \"temperature\" }, \"y\" : { \"field\" : \"classification\" } } This is the internal representation of a bar chart that averages temperature by classification. SVL turns this into the following SQL query SELECT AVG ( temperature ) AS x , classification AS y FROM bigfoot GROUP BY classification This is where FILTER and TRANSFORM SQL gets applied as well. This is the internal representation of a scatter plot that puts latitude on X and temperature on Y, but filters latitudes. { \"data\" : \"bigfoot\" , \"x\" : { \"field\" : \"latitude\" }, \"y\" : { \"field\" : \"temperature\" }, \"filter\" : \"latitude < 84\" } This is the query. SELECT latitude AS x , temperature AS y FROM bigfoot WHERE latitude < 84 Once the query is executed, the data is marshalled into a data structure that looks like this: { \"x\" : [ ... ], \"y\" : [ ... ] } There are variations of that based on whether there are SPLIT BY or COLOR BY arguments, but basically that's all there is to it. There's tons of edge cases and other weird stuff that happens here that makes the code a little tedious, but I think I can probably find a nice way to do it in the future. Combining Plots and Data So we have a flat list of plot specifiers, and a flat list of data representations. Both of these are completely internal representations; they're agnostic to the plotting machinery. This is the point where they combine to form Plotly graphs (as dictionaries, not Plotly's graph objs). There's a function for each plot type that combines the data and specifier into a plotly graph. It's a little tedious so I'm not going to go into the details of the Plotly graph specifiers - you can read about it here . The important part is, for each plot, we extract this information: { \"row_start\" : row_start , \"row_end\" : row_end , \"column_start\" : column_start , \"column_end\" : column_end , \"plotly\" : { ... } # This is a the plotly specifier. } Basically we have the plot's CSS grid position and the plot data structure itself. These plots, along with the number of columns and rows, are passed to the Jinja template. Jinja With the CSS grid position of each plot in place, the whole page is just a flat sequence of Plotly div elements that have the grid positions as CSS style elements. The identifiers for each div element is derived from the grid position. This is the whole thing. <!DOCTYPE html> <html> <head> <meta charset=\"UTF-8\"/> <title>SVL Plots</title> <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script> <style> .container { display: grid; grid-template-columns: repeat( {{ num_columns }} , minmax(300px, {{ 100 / num_columns }} vw)); grid-template-rows: repeat( {{ num_rows }} , minmax(300px, {{ 100 / num_rows }} vh)); } {% for plot in plots %} #p {{ plot.row_start }} _ {{ plot.column_start }} { grid-column-start: {{ plot.column_start }} ; grid-column-end: {{ plot.column_end }} ; grid-row-start: {{ plot.row_start }} ; grid-row-end: {{ plot.row_end }} ; } {% endfor %} </style> </head> <body> <div class=\"container\"> {% for plot in plots %} <div id=\"p {{ plot.row_start }} _ {{ plot.column_start }} \"> </div> {% endfor %} </div> <script> {% for plot in plots %} var plot_ {{ plot.row_start }} _ {{ plot.column_start }} = Plotly.newPlot( \"p {{ plot.row_start }} _ {{ plot.column_start }} \", {{ plot.plotly | tojson }} ); {% endfor %} </script> </body> </html> And that's it. Hopefully it's clear that elements are loosely coupled - in particular the data processor doesn't have to be SQLite and the final plot output doesn't have to be drawn by Plotly. If there's enough demand I could certainly see future work in expanding the plot renderers as well as additional data processors. The Whole Enchilada","title":"Under the Hood"},{"location":"reference/under_the_hood/#under-the-hood","text":"This document describes the structure of the compiler. I'll start by describing the compiler's stages in sequence, then present a diagram at the end with everything. The entire compiler is written in Python, with a sprinkling of HTML / JS to render the final HTML page.","title":"Under the Hood"},{"location":"reference/under_the_hood/#parsing","text":"The language itself is defined as an EBNF grammar designed to be parsed by the freaking awesome Lark parser. The grammar itself is defined in this file . This probably isn't the cleanest representation (I've never done this before / don't have formal CS training), but it gets the job done. Lark takes the grammar specification and the input script and parses that into a bunch of custom objects. I've implemented an adapter to convert those objects into a python dictionary that provides a tree-like representation of the plots. The reason this is a tree has to do with CONCAT( ... ) and ( ... ) . A chart is defined as either a raw plot, or a concatenation of plots. This means they can nest within one another, which makes them a tree. Concretely, given this script: DATASETS bigfoot \"bigfoot_sightings.csv\" CONCAT( SCATTER bigfoot X latitude Y temperature_mid BAR bigfoot X classification Y classification COUNT ) the resulting tree looks like: { \"datasets\" : { \"bigfoot\" : { \"file\" : \"bigfoot_sightings.csv\" } }, \"vcat\" : [{ \"hcat\" : [ { \"data\" : \"bigfoot\" , \"type\" : \"scatter\" , \"x\" : { \"field\" : \"latitude\" }, \"y\" : { \"field\" : \"temperature_mid\" } }, { \"data\" : \"bigfoot\" , \"type\" : \"bar\" , \"x\" : { \"field\" : \"classification\" }, \"y\" : { \"agg\" : \"COUNT\" , \"field\" : \"classification\" } } ] }] } The outermost vcat (vertical concatenation) is always there, and inside that there's an hcat (horizontal concatenation). Either of the plots inside the hcat could itself be an hcat or vcat ... and on and on.","title":"Parsing"},{"location":"reference/under_the_hood/#flattening-the-plot-tree","text":"Trees are nice inside a programming environment, but I need these plots to get rendered onto a web page, which means I need to project the tree onto a grid. I implemented plot layouts with CSS grids because they're pretty straightforward once you get your head around it. Basically, CSS grids need a layout declaration, and each element in the grid needs a position. So I need to go from tree of plots to a list of plots that have grid positions. I can traverse the tree and track the position as I go, but there's a minor hiccup: CSS grids are uniform , but our plots aren't. If I've got one plot on one row, then there's only one CSS column / row. If I've got one plot on the first row and two on the second (via CONCAT ), then I need CSS to have two columns and two rows. If I've got one plot on the first row and three plots on the second row, but the two on the right are stacked, then I need 4 columns and 4 rows... and I need to ensure that the top plot takes up 2 rows and 4 columns, and so forth. Concretely, given this tree (I've replaced the plot details with simple dicts for readability)... { \"vcat\" : [ { \"hcat\" : [ { \"plot\" : 1 }, { \"plot\" : 2 } ] }, { \"vcat\" : [ { \"plot\" : 3 }, { \"plot\" : 4 } ] } ] } This tree puts two side-by-side plots on the first row, and two vertical plots on the second row. As real output this would look weird, but it's a good example. The first row of plots take up one column and two rows each, while the second row of plots take up one row and two columns each. SVL flattens the above to this list. [ { \"plot\" : 1 , \"row_start\" : 0 , \"row_end\" : 2 , \"column_start\" : 0 , \"column_end\" : 1 }, { \"plot\" : 2 , \"row_start\" : 0 , \"row_end\" : 2 , \"column_start\" : 1 , \"column_end\" : 2 }, { \"plot\" : 3 , \"row_start\" : 2 , \"row_end\" : 3 , \"column_start\" : 0 , \"column_end\" : 2 }, { \"plot\" : 4 , \"row_start\" : 3 , \"row_end\" : 4 , \"column_start\" : 0 , \"column_end\" : 2 } ] This piece of the compiler is complicated. It took me over 2 months to get this right. The unit tests for this algorithm total up to almost 700 lines of code. It's the only time I've ever used TDD (it worked very well for this).","title":"Flattening the Plot Tree"},{"location":"reference/under_the_hood/#loading-the-sqlite-db","text":"This piece is pretty straightforward. Because I'm lazy efficient, I decided to use pandas to read the files and load the SQLite database. Files are loaded first, then the SQL datasets are constructed in the order they appear in the script.","title":"Loading the SQLite DB"},{"location":"reference/under_the_hood/#retrieving-the-plot-data","text":"This functionality is the proud home of probably the worst code of the whole compiler (I'm going to refactor it soon because it makes my eyes bleed), but the functionality in principle is simple. It translates the SVL plot specifier (after flattening) into a SQL query, then marshals those results into something that can be injected into a Plotly data structure. For example, consider the following plot. { \"data\" : \"bigfoot\" , \"type\" : \"bar\" , \"x\" : { \"agg\" : \"AVG\" , \"field\" : \"temperature\" }, \"y\" : { \"field\" : \"classification\" } } This is the internal representation of a bar chart that averages temperature by classification. SVL turns this into the following SQL query SELECT AVG ( temperature ) AS x , classification AS y FROM bigfoot GROUP BY classification This is where FILTER and TRANSFORM SQL gets applied as well. This is the internal representation of a scatter plot that puts latitude on X and temperature on Y, but filters latitudes. { \"data\" : \"bigfoot\" , \"x\" : { \"field\" : \"latitude\" }, \"y\" : { \"field\" : \"temperature\" }, \"filter\" : \"latitude < 84\" } This is the query. SELECT latitude AS x , temperature AS y FROM bigfoot WHERE latitude < 84 Once the query is executed, the data is marshalled into a data structure that looks like this: { \"x\" : [ ... ], \"y\" : [ ... ] } There are variations of that based on whether there are SPLIT BY or COLOR BY arguments, but basically that's all there is to it. There's tons of edge cases and other weird stuff that happens here that makes the code a little tedious, but I think I can probably find a nice way to do it in the future.","title":"Retrieving the Plot Data"},{"location":"reference/under_the_hood/#combining-plots-and-data","text":"So we have a flat list of plot specifiers, and a flat list of data representations. Both of these are completely internal representations; they're agnostic to the plotting machinery. This is the point where they combine to form Plotly graphs (as dictionaries, not Plotly's graph objs). There's a function for each plot type that combines the data and specifier into a plotly graph. It's a little tedious so I'm not going to go into the details of the Plotly graph specifiers - you can read about it here . The important part is, for each plot, we extract this information: { \"row_start\" : row_start , \"row_end\" : row_end , \"column_start\" : column_start , \"column_end\" : column_end , \"plotly\" : { ... } # This is a the plotly specifier. } Basically we have the plot's CSS grid position and the plot data structure itself. These plots, along with the number of columns and rows, are passed to the Jinja template.","title":"Combining Plots and Data"},{"location":"reference/under_the_hood/#jinja","text":"With the CSS grid position of each plot in place, the whole page is just a flat sequence of Plotly div elements that have the grid positions as CSS style elements. The identifiers for each div element is derived from the grid position. This is the whole thing. <!DOCTYPE html> <html> <head> <meta charset=\"UTF-8\"/> <title>SVL Plots</title> <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script> <style> .container { display: grid; grid-template-columns: repeat( {{ num_columns }} , minmax(300px, {{ 100 / num_columns }} vw)); grid-template-rows: repeat( {{ num_rows }} , minmax(300px, {{ 100 / num_rows }} vh)); } {% for plot in plots %} #p {{ plot.row_start }} _ {{ plot.column_start }} { grid-column-start: {{ plot.column_start }} ; grid-column-end: {{ plot.column_end }} ; grid-row-start: {{ plot.row_start }} ; grid-row-end: {{ plot.row_end }} ; } {% endfor %} </style> </head> <body> <div class=\"container\"> {% for plot in plots %} <div id=\"p {{ plot.row_start }} _ {{ plot.column_start }} \"> </div> {% endfor %} </div> <script> {% for plot in plots %} var plot_ {{ plot.row_start }} _ {{ plot.column_start }} = Plotly.newPlot( \"p {{ plot.row_start }} _ {{ plot.column_start }} \", {{ plot.plotly | tojson }} ); {% endfor %} </script> </body> </html> And that's it. Hopefully it's clear that elements are loosely coupled - in particular the data processor doesn't have to be SQLite and the final plot output doesn't have to be drawn by Plotly. If there's enough demand I could certainly see future work in expanding the plot renderers as well as additional data processors.","title":"Jinja"},{"location":"reference/under_the_hood/#the-whole-enchilada","text":"","title":"The Whole Enchilada"},{"location":"tutorials/advanced_svl/","text":"Advanced SVL The basic SVL tutorial covered how to make, customize and arrange plots. SVL also has advanced SQL-powered data processing capabilities that make it easy to adjust your datasets without writing a bunch of additional code. Before getting in to the SQL parts, there are a couple of things to cover first. This tutorial uses the same dataset as the basic tutorial. I'll go ahead and use the basic_tutorial.svl script from the basic SVL tutorial as a starting point. cp basic_tutorial.svl advanced_tutorial.svl Sorting Data Suppose I want to see which states have the most bigfoot sightings. That's pretty easy. Add this underneath the line chart. BAR bigfoot TITLE \"Bigfoot Sightings by State\" X state LABEL \"State\" Y state COUNT LABEL \"Number of Sightings\" It looks like this: Notice that it's unsorted. SVL supports sorting an axis as a modifier. BAR bigfoot TITLE \"Bigfoot Sightings by State\" X state LABEL \"State\" Y state COUNT LABEL \"Number of Sightings\" SORT DESC Now our bar chart looks like this: SORT must be followed by ASC or DESC . Here's the full script. DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification BAR bigfoot TITLE \"Bigfoot Sightings by State\" X state LABEL \"State\" Y state COUNT LABEL \"Number of Sightings\" SORT DESC CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 ( BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" Interactive version here Datasets at the Command Line Sometimes it might be convenient not to have the name of the file hard coded into the SVL script. For example, suppose you've got a pipeline that produces files with dates in the name. It would be nice if you could create the same visualizations and treat the file as a parameter. SVL supports passing in dataset file definitions from the command line. In fact, the DATASETS declaration is optional. -- No DATASETS! LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification BAR bigfoot TITLE \"Bigfoot Sightings by State\" X state LABEL \"State\" Y state COUNT LABEL \"Number of Sightings\" SORT DESC CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 ( BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" is what our Bigfoot SVL script looks like without a DATASETS declaration. It won't compile without one additional command line argument. svl advanced_tutorial.svl --dataset bigfoot=bigfoot_sightings.csv You can pass multiple files with different labels by repeating --dataset label=path for each file. For simplicity I haven't changed this in the advanced_tutorial.svl script, I just wanted to demonstrate what it would look like. Data in SVL Before proceeding with the next few topics it's worth describing a tiny bit what's under the hood when it processes data. I'll leave the gory parts to this section , but a quick description of how SVL processes and retrieves data for plots will make the next few topics easier. SVL's data processing is powered by SQLite. After the source code is parsed and checked for syntax errors, SVL assembles the datasets in the DATASETS declaration plus any that were passed in via command line and loads them into an in-memory SQLite database. For each plot, SVL constructs a SQL query to produce the data needed for the plot, executes it, and arranges it in a data structure that Plotly can understand. Doing data processing using SQLite has a couple of big advantages. If most of the data work is in SQL, then there's nothing specific about the data being \"in-memory\" or SQLite itself. In the future this keeps open the possibility of supporting other databases. SVL can inject SQL directly into the data processing queries for the plots. This means SVL can support filters and transformations on the data without the need for tons of additional syntax - you can use what you already know. The next three sections cover using FILTER to filter the data, using TRANSFORM to transform the data for an axis, and creating custom datasets within SVL by transforming the datasets that live in files. All three of these use the underlying SQLite processor to do the heavy lifting. Filtering Data In the last tutorial I mentioned our line chart had some outliers that were causing the plot to look funny. Let's fix that by applying a filter to the data for that plot. LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification -- The filter string gets pasted into a SQL WHERE clause. FILTER \"date > '1960-01-01'\" \ud83c\udf89 Much better! \ud83c\udf89 The most important thing to note about FILTER (and really all of SVL's SQL support) is that SVL has no idea what's in those quotes. It literally pastes the stuff in quotes right into the query. The field names of the dataset match the field names in the SQLite database. Other than that - there are no rules, so use with caution. I might have to rethink this when introducing remote data sources for security reasons, but for now it's only dangerous to you \ud83d\ude09. Transforming Data I have a confession to make - I like pie charts. The caveat is that I pretty much only like them for one thing: counting null values. As an engineer who has to send data-powered software into production environments, I count null values a lot . I want to rewrite our pie chart to count the number of null locations in the Bigfoot dataset. Thankfully SVL doesn't support SQL just for filters. It can also apply arbitrary SQL to transform an axis as well. Replace the existing pie chart in the advanced_tutorial.svl script with this. PIE bigfoot TITLE \"Number of Geocoded Sightings\" -- Yes line breaks do work. AXIS TRANSFORM \"CASE WHEN latitude IS NULL THEN 'No Location' ELSE 'Location' END\" HOLE 0.3 Just like with FILTER , everything in quotes after TRANSFORM literally gets pasted into a SQL query (this time it's a SELECT instead of WHERE). SVL has no idea what's in those quotes, so keeping it simple is probably a good idea. Also, TRANSFORM replaces a field specifier in an axis declaration. It can apply to X , Y , AXIS , COLOR BY , and SPLIT BY . Custom Datasets When SVL loads each dataset into the SQLite database, it creates a table with the same name as the dataset. Once all of the files have been loaded, SVL can actually create new tables from SQL queries on file-based datasets. This is useful if you can't get what you want from FILTER s, TRANSFORM s, or any of SVL's built in aggregation functions. Joining two files would be one example. To illustrate, suppose I want to aggregate the number of sightings by classification separate from the bar chart (maybe I want this precomputed because I'm going to plot it a whole lot or something). Then I'll need to construct a second dataset using SQL. This is done in the DATASETS declaration with the SQL keyword. DATASETS bigfoot \"bigfoot_sightings.csv\" -- Note the aggregation must be aliased so it's a valid SVL identifier. bigfoot_class_counts SQL \"SELECT classification, COUNT(*) AS count FROM bigfoot GROUP BY classification\" The bar chart can now reference the new dataset. BAR bigfoot_class_counts TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y count LABEL \"Number of Sightings\" The plot is the same as before. All Together In this section I've demonstrated the features of SVL that take advantage of the underlying SQLite-powered data processing. By allowing functions that can directly leverage SQL to be integrated with the language, SVL no longer has to provide a huge suite of data processing capability, and you the user do not have to learn yet another data processing language. SVL stays both small and flexible. Adding SQL commands does make things a little more complicated, but there will probably be cases where the tradeoff is worth it. Here's the final advanced_tutorial.svl script with all of the modifications in this section. DATASETS bigfoot \"bigfoot_sightings.csv\" -- Note the aggregation must be aliased to a valid SVL identifier. bigfoot_class_counts SQL \"SELECT classification, COUNT(*) AS count FROM bigfoot GROUP BY classification\" LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification -- The filter string gets pasted into a SQL WHERE clause. FILTER \"date > '1960-01-01'\" BAR bigfoot TITLE \"Bigfoot Sightings by State\" X state LABEL \"State\" Y state COUNT LABEL \"Number of Sightings\" SORT DESC CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 ( BAR bigfoot_class_counts TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y count LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Geocoded Sightings\" -- Yes line breaks do work. AXIS TRANSFORM \"CASE WHEN latitude IS NULL THEN 'No Location' ELSE 'Location' END\" HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" This script is just over 50 lines of very spread out code. The visualization looks like this. Interactive version here . This script demonstrates every syntax feature of the SVL language. Conclusion In addition to syntax for declaring datasets and creating / customizing charts, SVL also provides advanced data processing capability by exposing the underlying SQL processing engine directly. This provides an immense amount of flexibility for arranging the data in a way that best suits the charts without leaving SVL or adding a bunch of duplicate syntax. At this point you know the whole language. The final script in this tutorial touched every part of the SVL grammar. If you need a reference to the grammar, head on over to the language reference section. If you'd like to really know how SVL works from top to bottom, check out this article . Thanks for taking the time to walk through the SVL language. I hope you find yourself using it to make and share lots and lots of plots.","title":"Advanced SVL"},{"location":"tutorials/advanced_svl/#advanced-svl","text":"The basic SVL tutorial covered how to make, customize and arrange plots. SVL also has advanced SQL-powered data processing capabilities that make it easy to adjust your datasets without writing a bunch of additional code. Before getting in to the SQL parts, there are a couple of things to cover first. This tutorial uses the same dataset as the basic tutorial. I'll go ahead and use the basic_tutorial.svl script from the basic SVL tutorial as a starting point. cp basic_tutorial.svl advanced_tutorial.svl","title":"Advanced SVL"},{"location":"tutorials/advanced_svl/#sorting-data","text":"Suppose I want to see which states have the most bigfoot sightings. That's pretty easy. Add this underneath the line chart. BAR bigfoot TITLE \"Bigfoot Sightings by State\" X state LABEL \"State\" Y state COUNT LABEL \"Number of Sightings\" It looks like this: Notice that it's unsorted. SVL supports sorting an axis as a modifier. BAR bigfoot TITLE \"Bigfoot Sightings by State\" X state LABEL \"State\" Y state COUNT LABEL \"Number of Sightings\" SORT DESC Now our bar chart looks like this: SORT must be followed by ASC or DESC . Here's the full script. DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification BAR bigfoot TITLE \"Bigfoot Sightings by State\" X state LABEL \"State\" Y state COUNT LABEL \"Number of Sightings\" SORT DESC CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 ( BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" Interactive version here","title":"Sorting Data"},{"location":"tutorials/advanced_svl/#datasets-at-the-command-line","text":"Sometimes it might be convenient not to have the name of the file hard coded into the SVL script. For example, suppose you've got a pipeline that produces files with dates in the name. It would be nice if you could create the same visualizations and treat the file as a parameter. SVL supports passing in dataset file definitions from the command line. In fact, the DATASETS declaration is optional. -- No DATASETS! LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification BAR bigfoot TITLE \"Bigfoot Sightings by State\" X state LABEL \"State\" Y state COUNT LABEL \"Number of Sightings\" SORT DESC CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 ( BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" is what our Bigfoot SVL script looks like without a DATASETS declaration. It won't compile without one additional command line argument. svl advanced_tutorial.svl --dataset bigfoot=bigfoot_sightings.csv You can pass multiple files with different labels by repeating --dataset label=path for each file. For simplicity I haven't changed this in the advanced_tutorial.svl script, I just wanted to demonstrate what it would look like.","title":"Datasets at the Command Line"},{"location":"tutorials/advanced_svl/#data-in-svl","text":"Before proceeding with the next few topics it's worth describing a tiny bit what's under the hood when it processes data. I'll leave the gory parts to this section , but a quick description of how SVL processes and retrieves data for plots will make the next few topics easier. SVL's data processing is powered by SQLite. After the source code is parsed and checked for syntax errors, SVL assembles the datasets in the DATASETS declaration plus any that were passed in via command line and loads them into an in-memory SQLite database. For each plot, SVL constructs a SQL query to produce the data needed for the plot, executes it, and arranges it in a data structure that Plotly can understand. Doing data processing using SQLite has a couple of big advantages. If most of the data work is in SQL, then there's nothing specific about the data being \"in-memory\" or SQLite itself. In the future this keeps open the possibility of supporting other databases. SVL can inject SQL directly into the data processing queries for the plots. This means SVL can support filters and transformations on the data without the need for tons of additional syntax - you can use what you already know. The next three sections cover using FILTER to filter the data, using TRANSFORM to transform the data for an axis, and creating custom datasets within SVL by transforming the datasets that live in files. All three of these use the underlying SQLite processor to do the heavy lifting.","title":"Data in SVL"},{"location":"tutorials/advanced_svl/#filtering-data","text":"In the last tutorial I mentioned our line chart had some outliers that were causing the plot to look funny. Let's fix that by applying a filter to the data for that plot. LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification -- The filter string gets pasted into a SQL WHERE clause. FILTER \"date > '1960-01-01'\" \ud83c\udf89 Much better! \ud83c\udf89 The most important thing to note about FILTER (and really all of SVL's SQL support) is that SVL has no idea what's in those quotes. It literally pastes the stuff in quotes right into the query. The field names of the dataset match the field names in the SQLite database. Other than that - there are no rules, so use with caution. I might have to rethink this when introducing remote data sources for security reasons, but for now it's only dangerous to you \ud83d\ude09.","title":"Filtering Data"},{"location":"tutorials/advanced_svl/#transforming-data","text":"I have a confession to make - I like pie charts. The caveat is that I pretty much only like them for one thing: counting null values. As an engineer who has to send data-powered software into production environments, I count null values a lot . I want to rewrite our pie chart to count the number of null locations in the Bigfoot dataset. Thankfully SVL doesn't support SQL just for filters. It can also apply arbitrary SQL to transform an axis as well. Replace the existing pie chart in the advanced_tutorial.svl script with this. PIE bigfoot TITLE \"Number of Geocoded Sightings\" -- Yes line breaks do work. AXIS TRANSFORM \"CASE WHEN latitude IS NULL THEN 'No Location' ELSE 'Location' END\" HOLE 0.3 Just like with FILTER , everything in quotes after TRANSFORM literally gets pasted into a SQL query (this time it's a SELECT instead of WHERE). SVL has no idea what's in those quotes, so keeping it simple is probably a good idea. Also, TRANSFORM replaces a field specifier in an axis declaration. It can apply to X , Y , AXIS , COLOR BY , and SPLIT BY .","title":"Transforming Data"},{"location":"tutorials/advanced_svl/#custom-datasets","text":"When SVL loads each dataset into the SQLite database, it creates a table with the same name as the dataset. Once all of the files have been loaded, SVL can actually create new tables from SQL queries on file-based datasets. This is useful if you can't get what you want from FILTER s, TRANSFORM s, or any of SVL's built in aggregation functions. Joining two files would be one example. To illustrate, suppose I want to aggregate the number of sightings by classification separate from the bar chart (maybe I want this precomputed because I'm going to plot it a whole lot or something). Then I'll need to construct a second dataset using SQL. This is done in the DATASETS declaration with the SQL keyword. DATASETS bigfoot \"bigfoot_sightings.csv\" -- Note the aggregation must be aliased so it's a valid SVL identifier. bigfoot_class_counts SQL \"SELECT classification, COUNT(*) AS count FROM bigfoot GROUP BY classification\" The bar chart can now reference the new dataset. BAR bigfoot_class_counts TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y count LABEL \"Number of Sightings\" The plot is the same as before.","title":"Custom Datasets"},{"location":"tutorials/advanced_svl/#all-together","text":"In this section I've demonstrated the features of SVL that take advantage of the underlying SQLite-powered data processing. By allowing functions that can directly leverage SQL to be integrated with the language, SVL no longer has to provide a huge suite of data processing capability, and you the user do not have to learn yet another data processing language. SVL stays both small and flexible. Adding SQL commands does make things a little more complicated, but there will probably be cases where the tradeoff is worth it. Here's the final advanced_tutorial.svl script with all of the modifications in this section. DATASETS bigfoot \"bigfoot_sightings.csv\" -- Note the aggregation must be aliased to a valid SVL identifier. bigfoot_class_counts SQL \"SELECT classification, COUNT(*) AS count FROM bigfoot GROUP BY classification\" LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification -- The filter string gets pasted into a SQL WHERE clause. FILTER \"date > '1960-01-01'\" BAR bigfoot TITLE \"Bigfoot Sightings by State\" X state LABEL \"State\" Y state COUNT LABEL \"Number of Sightings\" SORT DESC CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 ( BAR bigfoot_class_counts TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y count LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Geocoded Sightings\" -- Yes line breaks do work. AXIS TRANSFORM \"CASE WHEN latitude IS NULL THEN 'No Location' ELSE 'Location' END\" HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" This script is just over 50 lines of very spread out code. The visualization looks like this. Interactive version here . This script demonstrates every syntax feature of the SVL language.","title":"All Together"},{"location":"tutorials/advanced_svl/#conclusion","text":"In addition to syntax for declaring datasets and creating / customizing charts, SVL also provides advanced data processing capability by exposing the underlying SQL processing engine directly. This provides an immense amount of flexibility for arranging the data in a way that best suits the charts without leaving SVL or adding a bunch of duplicate syntax. At this point you know the whole language. The final script in this tutorial touched every part of the SVL grammar. If you need a reference to the grammar, head on over to the language reference section. If you'd like to really know how SVL works from top to bottom, check out this article . Thanks for taking the time to walk through the SVL language. I hope you find yourself using it to make and share lots and lots of plots.","title":"Conclusion"},{"location":"tutorials/basic_svl/","text":"Basic SVL This tutorial will walk through the basics of creating SVL programs. By the end of this tutorial you will know how to declare datasets create all chart types customize charts with titles and axis labels split dataset by a categorical variable color a dataset by a continuous variable normalize temporal fields arrange multiple plots in a single output file And you will learn all of these things working on a real world not-really-cleaned dataset of Bigfoot sightings . This dataset was collected by the Bigfoot Field Researchers Organization ( BFRO ). Start by downloading that dataset into the current directory. wget https://github.com/timothyrenner/svl/raw/docs/sample_data/bigfoot_sightings.csv The tutorial's been designed to operate on a single file, but it can be split up too. I'll include a complete version of the state of the file (which I'll name basic_tutorial.svl ) at the end of each section. Boring Stuff Before I start there's boring stuff I need to cover. All keywords in SVL are case- insensitive , but field names, file names, and anything in quotes are not. By convention I will capitalize keywords but it's not required. Comments start with -- and extend to the end of the line. All dataset and field names (basically anything not in quotes) must start with an underscore or letter, and can only contain letters, underscores or digits. SVL is not sensitive to tabs or newlines. The entire program could be written on one line if you wanted. Aside from field and dataset names being case sensitive, this is pretty much just like SQL. Datasets An SVL program usually starts with a datset declaration. This tells the compiler where your datsets live and assigns them a label. This isn't required - datsets can be declared as compiler command line arguments, but that will be covered in the advanced SVL tutorial. If an SVL program has a DATASETS declaration, it must be at the beginning of the program. It looks like this. DATASETS bigfoot \"bigfoot_sightings.csv\" The name of the dataset is an identifier, and the name of the file must be in quotes. Naturally this SVL program won't compile - we need some plots first. The next section will walk you through the plot types. Chart Types SVL supports six plot types: histogram, scatter, bar, line, number (for all your big number\u00a9\ufe0f needs), and ... my personal favorite ... pie charts. Don't worry, you can add holes to your pie charts so your friends won't judge. HISTOGRAM Histograms are for binning a single variable. Let's say we want to (and we definitely do) figure out if more bigfoot sightings occur during a particular phase of the moon. Add this to your basic_tutorial.svl file under the DATASETS declaration. HISTOGRAM bigfoot -- same name as DATASETS X moon_phase -- can specify Y for vertical histogram STEP 0.1 -- optional, can also specify BINS to set number of bins Compile it with svl basic_tutorial.svl and you should see A couple of things to note: Axes are declared by X or Y followed by the field. This is true of all plot types except pie charts. Only histograms take a STEP or BINS , but they aren't required. SCATTER Scatter plots need two axes. Suppose we want to see if the southern Sasquatch (colloquially referred to as \"skunk ape\") prefers warmer temperatures farther south, or if they prefer the same temperature as their Pacific Northwest cousins). Add this to basic_tutorial.svl underneath the histogram. SCATTER bigfoot X latitude Y temperature_mid That's it. Compile again and it'll appear right under the histogram. BAR Bar charts are basically declared the same way as scatter plots, except that they usually appear with aggregations. Bigfoot sighting reports are classified by three types: A, B and C. A is direct evidence, B is indirect evidence, and C is a secondhand account. Suppose we want to count the number of sightings with each classification rating. BAR bigfoot X classification Y number COUNT -- COUNT is an aggregation, number is a field in the dataset. This plot will count the number of reports for each classification. A couple of things to note: There are five aggregations: COUNT , MIN , MAX , AVG , SUM . More will probably be added in the future. It's probably not a good idea to bar chart continuous variables, but SVL won't stop you. COUNT shouldn't need the field label but for technical reasons it does. I'll probably fix this at some point in the near future. LINE Line charts, like bar charts, usually appear with aggregations. They are good for plotting things like time. If we want to know the number of bigfoot sightings over time, this plot will get us there. LINE bigfoot X date BY YEAR Y number COUNT This plot counts the number of sightings by year. This plot also introduces a temporal transformation . Basically, SVL truncates each date at the year and then counts each year's worth of sightings. Currently only YYYY-mm-ddTH:MM:S format is supported but it should be straightforward to support custom formats in the future. The following temporal transformations are available: YEAR , MONTH , DAY , HOUR , MINUTE , SECOND . Temporal transformations can be applied to X , Y , COLOR BY and SPLIT BY axes (more on those last two shortly). PIE Pie charts are a little different from the others. Basically they count the different values of the axis we select. Suppose we wanted to view the proportion of sighting classifications. PIE bigfoot AXIS classification HOLE 0.3 -- HOLE is only available for pie charts. We get this Note: Pie charts require AXIS instead of X or Y . HOLE only applies to pie charts, and must be values between zero and one. NUMBER Number was added a little later than the others, but it's pretty useful. It takes a single value and prints it. That's all. If we want to show a big number\u00a9\ufe0f for the bigfoot sightings, we could do this. NUMBER bigfoot VALUE number COUNT We get this: Note: Whatever's in VALUE needs to be a single number. If not SVL will raise an error. In Summary Let's tally up our Bigfoot knowledge. DATASETS bigfoot \"bigfoot_sightings.csv\" -- Keep in mind the line breaks and tabs are only to make things visually -- coherent. They're not required by language syntax. HISTOGRAM bigfoot -- same name as DATASETS X moon_phase -- can specify Y for vertical histogram STEP 0 . 1 -- optional, can also specify BINS to set number of bins SCATTER bigfoot X latitude Y temperature_mid BAR bigfoot X classification Y number COUNT -- COUNT is an aggregation, number is a field in the dataset. LINE bigfoot X date BY YEAR Y number COUNT PIE bigfoot AXIS classification HOLE 0 . 3 -- HOLE is only available for pie charts. And this is what it looks like: You can view an interactive version here . A few things that jump out: The titles and axis labels aren't pretty. I'll cover how to do that next. The plots look stretched and weird. This is partly due to browser window width, and partly due to the fact that some of those plots (looking at you pie chart) don't need that much screen real estate. The \"Plot Arrangement\" section covers this. What if you want multiple lines / bars /etc on one plot - like number of sightings per classification? SPLIT BY and it's cousin COLOR BY cover how these additional axes work. Customizing Charts - Titles and Axis Labels SVL provides default titles and labels for axes based on the fields in the file, but those aren't the prettiest. To add some class to your plots, SVL provides the TITLE and LABEL keywords. Here's a beautified version of our histogram. HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0.1 It looks like this: TITLE can appear anywhere after the plot declaration (i.e. HISTOGRAM bigfoot ). LABEL can appear anywhere after the axis declaration (i.e. X moon_phase ). LABEL is valid SVL syntax for SPLIT BY but doesn't do anything for Plotly, because they don't currently have a straightforward way to add legend titles to plots. \u2705 VALID AXIS LABEL : X moon_phase LABEL \"Moon Phase\" \u274c INVALID AXIS LABEL : X LABEL \"Moon Phase\" moon_phase For completeness here's a fully beautified example of our earlier results. DATASETS -- Path is a little different from tutorial. bigfoot \"sample_data/bigfoot_sightings.csv\" HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0.1 SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" LINE bigfoot X date BY YEAR LABEL \"Year of Sighting\" TITLE \"Bigfoot Sightings by Year\" -- TITLE can go between axes nbd. Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification LABEL \"This gets ignored\" HOLE 0.3 You can see an interactive version of this visualization here . Plot Arrangement So far we've been placing the plots one after the other, and SVL has just stacked them. SVL provides a significant amount of control over how plots are laid out, however. In my opinion this is the coolest part of the language. SVL has a couple of ways of arranging plots to help you make the most of your screen real estate. SVL supports both vertical and horizontal concatenation, and allows these concatenations to be nested. The only plots in basic_tutorial.svl that really need the whole width of the screen are the line chart and scatter plot; the others can use a shrinking. DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot X date BY YEAR LABEL \"Year of Sighting\" TITLE \"Bigfoot Sightings by Year\" Y number COUNT LABEL \"Number of Sightings\" -- The CONCAT function performs a horizontal concatenation. CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification LABEL \"This gets ignored\" HOLE 0 . 3 ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" What I've done is switched the order of the plots by putting the line on top and the scatter on the bottom, and placing the bar, pie and histogram in the middle wrapped in a function called CONCAT . CONCAT horizonally concatenates plots, placing them on the same row. The above chart looks like this. View an interactive version here . Pretty sweet right? Think of things this way - at the top \"level\" of nesting there are three rows. The first row haw one plot, so it gets the full width of the page. The middle row has three plots that are horizontally concatenated, so each plot gets a third of the width. The final row just has one, so it takes the full screen. Let's say we want that histogram to take a little more space, and the bar / pie charts to take a little less. We can nest concatenations. Check this out. DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot X date BY YEAR LABEL \"Year of Sighting\" TITLE \"Bigfoot Sightings by Year\" Y number COUNT LABEL \"Number of Sightings\" CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 CONCAT ( BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification LABEL \"This gets ignored\" HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" What do you think it will look like? The top and bottom rows are the same, but the middle row is now split twice - one half is the histogram, and the other half is split between the bar chart and the pie chart. That is what we see (interactive example here ), but now there's an unintended side effect: the plot titles are cut off because there's not enough width. Resizing the browser can fix this, but we can also change the concatenation of those two plots from a horizontal one to a vertical one. Vertical concatenations are implicit at the top level, but inside a CONCAT there needs to be something to denote vertical vs horizontal concatenation. This is done using parens. DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot X date BY YEAR LABEL \"Year of Sighting\" TITLE \"Bigfoot Sightings by Year\" Y number COUNT LABEL \"Number of Sightings\" CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 -- Same as before, but with CONCAT removed. Now these two are vertically -- stacked. ( BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification LABEL \"This gets ignored\" HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" Interactive version here . Not only did the bar and pie charts stack, every row got taller making the whole page bigger. This happens because there's a minimum plot height. When the most nested plot reaches that minimum height, the entire document will resize to make sure everything remains proportional to what's in the script. Additional Axes: SPLIT BY and COLOR BY So now we know a thing or two about Bigfoot - can we go deeper? Well for one thing it might be worth checking out how the number of sightings by time breaks down by sighting classification. For that we'd need three lines. SVL allows us to split a plot by a field's values using a special axis specifier called ... SPLIT BY . Focusing on just the line plot, LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification This splits the data into three lines, one for each classification value. SPLIT BY is perfect for categorical variables - what about continuous ones? Suppose we want to overlay the moon phase onto the scatter plot. Then we'd know for sure if more Bigfoot sightings in Florida happened during a full moon (be honest ... you think it's true). SVL also has syntax for that - COLOR BY colors the existing points by the specified field. SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" For COLOR BY , you can optionally provide a color scale. It must appear after the axis declaration before any modifiers. \u2705 VALID COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" \u274c INVALID COLOR BY moon_phase LABEL \"Moon Phase\" \"YlOrRd\" \u274c INVALID COLOR BY \"YlOrRd\" moon_phase LABEL \"Moon Phase\" All together, the script looks like this... DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 ( BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" ... and produces plots that look like this: View an interactive version here . Conclusion That's it for the basic SVL tutorial. Here's what we covered. The structure of an SVL program. The five plot types: histogram, bar, scatter, line and pie. Customizing plots with titles and axis labels. Arranging plots with CONCAT . Additional axes with SPLIT BY and COLOR BY . There are a few questions this tutorial doesn't answer. What if I want to sort the results of a plot? That line plot has some outliers on the X axis. What if I want to filter the results of a plot? What if I don't want to hard code the file name in the script? What if I want to transform the data with something other than a temporal transformation? SVL supports all of the above. That's all covered in the Advanced SVL tutorial.","title":"Basic SVL"},{"location":"tutorials/basic_svl/#basic-svl","text":"This tutorial will walk through the basics of creating SVL programs. By the end of this tutorial you will know how to declare datasets create all chart types customize charts with titles and axis labels split dataset by a categorical variable color a dataset by a continuous variable normalize temporal fields arrange multiple plots in a single output file And you will learn all of these things working on a real world not-really-cleaned dataset of Bigfoot sightings . This dataset was collected by the Bigfoot Field Researchers Organization ( BFRO ). Start by downloading that dataset into the current directory. wget https://github.com/timothyrenner/svl/raw/docs/sample_data/bigfoot_sightings.csv The tutorial's been designed to operate on a single file, but it can be split up too. I'll include a complete version of the state of the file (which I'll name basic_tutorial.svl ) at the end of each section.","title":"Basic SVL"},{"location":"tutorials/basic_svl/#boring-stuff","text":"Before I start there's boring stuff I need to cover. All keywords in SVL are case- insensitive , but field names, file names, and anything in quotes are not. By convention I will capitalize keywords but it's not required. Comments start with -- and extend to the end of the line. All dataset and field names (basically anything not in quotes) must start with an underscore or letter, and can only contain letters, underscores or digits. SVL is not sensitive to tabs or newlines. The entire program could be written on one line if you wanted. Aside from field and dataset names being case sensitive, this is pretty much just like SQL.","title":"Boring Stuff"},{"location":"tutorials/basic_svl/#datasets","text":"An SVL program usually starts with a datset declaration. This tells the compiler where your datsets live and assigns them a label. This isn't required - datsets can be declared as compiler command line arguments, but that will be covered in the advanced SVL tutorial. If an SVL program has a DATASETS declaration, it must be at the beginning of the program. It looks like this. DATASETS bigfoot \"bigfoot_sightings.csv\" The name of the dataset is an identifier, and the name of the file must be in quotes. Naturally this SVL program won't compile - we need some plots first. The next section will walk you through the plot types.","title":"Datasets"},{"location":"tutorials/basic_svl/#chart-types","text":"SVL supports six plot types: histogram, scatter, bar, line, number (for all your big number\u00a9\ufe0f needs), and ... my personal favorite ... pie charts. Don't worry, you can add holes to your pie charts so your friends won't judge.","title":"Chart Types"},{"location":"tutorials/basic_svl/#histogram","text":"Histograms are for binning a single variable. Let's say we want to (and we definitely do) figure out if more bigfoot sightings occur during a particular phase of the moon. Add this to your basic_tutorial.svl file under the DATASETS declaration. HISTOGRAM bigfoot -- same name as DATASETS X moon_phase -- can specify Y for vertical histogram STEP 0.1 -- optional, can also specify BINS to set number of bins Compile it with svl basic_tutorial.svl and you should see A couple of things to note: Axes are declared by X or Y followed by the field. This is true of all plot types except pie charts. Only histograms take a STEP or BINS , but they aren't required.","title":"HISTOGRAM"},{"location":"tutorials/basic_svl/#scatter","text":"Scatter plots need two axes. Suppose we want to see if the southern Sasquatch (colloquially referred to as \"skunk ape\") prefers warmer temperatures farther south, or if they prefer the same temperature as their Pacific Northwest cousins). Add this to basic_tutorial.svl underneath the histogram. SCATTER bigfoot X latitude Y temperature_mid That's it. Compile again and it'll appear right under the histogram.","title":"SCATTER"},{"location":"tutorials/basic_svl/#bar","text":"Bar charts are basically declared the same way as scatter plots, except that they usually appear with aggregations. Bigfoot sighting reports are classified by three types: A, B and C. A is direct evidence, B is indirect evidence, and C is a secondhand account. Suppose we want to count the number of sightings with each classification rating. BAR bigfoot X classification Y number COUNT -- COUNT is an aggregation, number is a field in the dataset. This plot will count the number of reports for each classification. A couple of things to note: There are five aggregations: COUNT , MIN , MAX , AVG , SUM . More will probably be added in the future. It's probably not a good idea to bar chart continuous variables, but SVL won't stop you. COUNT shouldn't need the field label but for technical reasons it does. I'll probably fix this at some point in the near future.","title":"BAR"},{"location":"tutorials/basic_svl/#line","text":"Line charts, like bar charts, usually appear with aggregations. They are good for plotting things like time. If we want to know the number of bigfoot sightings over time, this plot will get us there. LINE bigfoot X date BY YEAR Y number COUNT This plot counts the number of sightings by year. This plot also introduces a temporal transformation . Basically, SVL truncates each date at the year and then counts each year's worth of sightings. Currently only YYYY-mm-ddTH:MM:S format is supported but it should be straightforward to support custom formats in the future. The following temporal transformations are available: YEAR , MONTH , DAY , HOUR , MINUTE , SECOND . Temporal transformations can be applied to X , Y , COLOR BY and SPLIT BY axes (more on those last two shortly).","title":"LINE"},{"location":"tutorials/basic_svl/#pie","text":"Pie charts are a little different from the others. Basically they count the different values of the axis we select. Suppose we wanted to view the proportion of sighting classifications. PIE bigfoot AXIS classification HOLE 0.3 -- HOLE is only available for pie charts. We get this Note: Pie charts require AXIS instead of X or Y . HOLE only applies to pie charts, and must be values between zero and one.","title":"PIE"},{"location":"tutorials/basic_svl/#number","text":"Number was added a little later than the others, but it's pretty useful. It takes a single value and prints it. That's all. If we want to show a big number\u00a9\ufe0f for the bigfoot sightings, we could do this. NUMBER bigfoot VALUE number COUNT We get this: Note: Whatever's in VALUE needs to be a single number. If not SVL will raise an error.","title":"NUMBER"},{"location":"tutorials/basic_svl/#in-summary","text":"Let's tally up our Bigfoot knowledge. DATASETS bigfoot \"bigfoot_sightings.csv\" -- Keep in mind the line breaks and tabs are only to make things visually -- coherent. They're not required by language syntax. HISTOGRAM bigfoot -- same name as DATASETS X moon_phase -- can specify Y for vertical histogram STEP 0 . 1 -- optional, can also specify BINS to set number of bins SCATTER bigfoot X latitude Y temperature_mid BAR bigfoot X classification Y number COUNT -- COUNT is an aggregation, number is a field in the dataset. LINE bigfoot X date BY YEAR Y number COUNT PIE bigfoot AXIS classification HOLE 0 . 3 -- HOLE is only available for pie charts. And this is what it looks like: You can view an interactive version here . A few things that jump out: The titles and axis labels aren't pretty. I'll cover how to do that next. The plots look stretched and weird. This is partly due to browser window width, and partly due to the fact that some of those plots (looking at you pie chart) don't need that much screen real estate. The \"Plot Arrangement\" section covers this. What if you want multiple lines / bars /etc on one plot - like number of sightings per classification? SPLIT BY and it's cousin COLOR BY cover how these additional axes work.","title":"In Summary"},{"location":"tutorials/basic_svl/#customizing-charts-titles-and-axis-labels","text":"SVL provides default titles and labels for axes based on the fields in the file, but those aren't the prettiest. To add some class to your plots, SVL provides the TITLE and LABEL keywords. Here's a beautified version of our histogram. HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0.1 It looks like this: TITLE can appear anywhere after the plot declaration (i.e. HISTOGRAM bigfoot ). LABEL can appear anywhere after the axis declaration (i.e. X moon_phase ). LABEL is valid SVL syntax for SPLIT BY but doesn't do anything for Plotly, because they don't currently have a straightforward way to add legend titles to plots. \u2705 VALID AXIS LABEL : X moon_phase LABEL \"Moon Phase\" \u274c INVALID AXIS LABEL : X LABEL \"Moon Phase\" moon_phase For completeness here's a fully beautified example of our earlier results. DATASETS -- Path is a little different from tutorial. bigfoot \"sample_data/bigfoot_sightings.csv\" HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0.1 SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" LINE bigfoot X date BY YEAR LABEL \"Year of Sighting\" TITLE \"Bigfoot Sightings by Year\" -- TITLE can go between axes nbd. Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification LABEL \"This gets ignored\" HOLE 0.3 You can see an interactive version of this visualization here .","title":"Customizing Charts - Titles and Axis Labels"},{"location":"tutorials/basic_svl/#plot-arrangement","text":"So far we've been placing the plots one after the other, and SVL has just stacked them. SVL provides a significant amount of control over how plots are laid out, however. In my opinion this is the coolest part of the language. SVL has a couple of ways of arranging plots to help you make the most of your screen real estate. SVL supports both vertical and horizontal concatenation, and allows these concatenations to be nested. The only plots in basic_tutorial.svl that really need the whole width of the screen are the line chart and scatter plot; the others can use a shrinking. DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot X date BY YEAR LABEL \"Year of Sighting\" TITLE \"Bigfoot Sightings by Year\" Y number COUNT LABEL \"Number of Sightings\" -- The CONCAT function performs a horizontal concatenation. CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification LABEL \"This gets ignored\" HOLE 0 . 3 ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" What I've done is switched the order of the plots by putting the line on top and the scatter on the bottom, and placing the bar, pie and histogram in the middle wrapped in a function called CONCAT . CONCAT horizonally concatenates plots, placing them on the same row. The above chart looks like this. View an interactive version here . Pretty sweet right? Think of things this way - at the top \"level\" of nesting there are three rows. The first row haw one plot, so it gets the full width of the page. The middle row has three plots that are horizontally concatenated, so each plot gets a third of the width. The final row just has one, so it takes the full screen. Let's say we want that histogram to take a little more space, and the bar / pie charts to take a little less. We can nest concatenations. Check this out. DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot X date BY YEAR LABEL \"Year of Sighting\" TITLE \"Bigfoot Sightings by Year\" Y number COUNT LABEL \"Number of Sightings\" CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 CONCAT ( BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification LABEL \"This gets ignored\" HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" What do you think it will look like? The top and bottom rows are the same, but the middle row is now split twice - one half is the histogram, and the other half is split between the bar chart and the pie chart. That is what we see (interactive example here ), but now there's an unintended side effect: the plot titles are cut off because there's not enough width. Resizing the browser can fix this, but we can also change the concatenation of those two plots from a horizontal one to a vertical one. Vertical concatenations are implicit at the top level, but inside a CONCAT there needs to be something to denote vertical vs horizontal concatenation. This is done using parens. DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot X date BY YEAR LABEL \"Year of Sighting\" TITLE \"Bigfoot Sightings by Year\" Y number COUNT LABEL \"Number of Sightings\" CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 -- Same as before, but with CONCAT removed. Now these two are vertically -- stacked. ( BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification LABEL \"This gets ignored\" HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" Interactive version here . Not only did the bar and pie charts stack, every row got taller making the whole page bigger. This happens because there's a minimum plot height. When the most nested plot reaches that minimum height, the entire document will resize to make sure everything remains proportional to what's in the script.","title":"Plot Arrangement"},{"location":"tutorials/basic_svl/#additional-axes-split-by-and-color-by","text":"So now we know a thing or two about Bigfoot - can we go deeper? Well for one thing it might be worth checking out how the number of sightings by time breaks down by sighting classification. For that we'd need three lines. SVL allows us to split a plot by a field's values using a special axis specifier called ... SPLIT BY . Focusing on just the line plot, LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification This splits the data into three lines, one for each classification value. SPLIT BY is perfect for categorical variables - what about continuous ones? Suppose we want to overlay the moon phase onto the scatter plot. Then we'd know for sure if more Bigfoot sightings in Florida happened during a full moon (be honest ... you think it's true). SVL also has syntax for that - COLOR BY colors the existing points by the specified field. SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" For COLOR BY , you can optionally provide a color scale. It must appear after the axis declaration before any modifiers. \u2705 VALID COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" \u274c INVALID COLOR BY moon_phase LABEL \"Moon Phase\" \"YlOrRd\" \u274c INVALID COLOR BY \"YlOrRd\" moon_phase LABEL \"Moon Phase\" All together, the script looks like this... DATASETS bigfoot \"bigfoot_sightings.csv\" LINE bigfoot TITLE \"Bigfoot Sightings by Year\" X date BY YEAR LABEL \"Year of Sighting\" Y number COUNT LABEL \"Number of Sightings\" SPLIT BY classification CONCAT ( HISTOGRAM bigfoot TITLE \"Bigfoot Sighting Moon Phases\" X moon_phase LABEL \"Moon Phase\" STEP 0 . 1 ( BAR bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" X classification LABEL \"Sighting Classification\" Y number COUNT LABEL \"Number of Sightings\" PIE bigfoot TITLE \"Number of Bigfoot Sightings by Classification\" AXIS classification HOLE 0 . 3 ) ) SCATTER bigfoot TITLE \"Bigfoot Sighting Temperature by Latitude\" X latitude LABEL \"Latitude\" Y temperature_mid LABEL \"Temperature (F)\" COLOR BY moon_phase \"YlOrRd\" LABEL \"Moon Phase\" ... and produces plots that look like this: View an interactive version here .","title":"Additional Axes: SPLIT BY and COLOR BY"},{"location":"tutorials/basic_svl/#conclusion","text":"That's it for the basic SVL tutorial. Here's what we covered. The structure of an SVL program. The five plot types: histogram, bar, scatter, line and pie. Customizing plots with titles and axis labels. Arranging plots with CONCAT . Additional axes with SPLIT BY and COLOR BY . There are a few questions this tutorial doesn't answer. What if I want to sort the results of a plot? That line plot has some outliers on the X axis. What if I want to filter the results of a plot? What if I don't want to hard code the file name in the script? What if I want to transform the data with something other than a temporal transformation? SVL supports all of the above. That's all covered in the Advanced SVL tutorial.","title":"Conclusion"}]}